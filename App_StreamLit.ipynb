{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlitNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading streamlit-0.82.0-py2.py3-none-any.whl (8.2 MB)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.1.0-py3-none-any.whl (727 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\rj\\anaconda3\\lib\\site-packages (from streamlit) (2.8.1)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from streamlit) (6.0.4)\n",
      "Collecting blinker\n",
      "\n",
      "  Downloading blinker-1.4.tar.gz (111 kB)\n",
      "Collecting tzlocal\n",
      "  Downloading tzlocal-2.1-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from streamlit) (3.15.6)\n",
      "Requirement already satisfied: pandas>=0.21.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from streamlit) (1.1.3)\n",
      "Collecting validators\n",
      "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: cachetools>=4.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from streamlit) (4.2.1)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.6.2-py2.py3-none-any.whl (4.2 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\rj\\anaconda3\\lib\\site-packages (from streamlit) (1.19.2)\n",
      "Collecting base58\n",
      "  Downloading base58-2.1.0-py3-none-any.whl (5.6 kB)\n",
      "Requirement already satisfied: watchdog; platform_system != \"Darwin\" in c:\\users\\rj\\anaconda3\\lib\\site-packages (from streamlit) (0.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\rj\\anaconda3\\lib\\site-packages (from streamlit) (2.24.0)\n",
      "Requirement already satisfied: click<8.0,>=7.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from streamlit) (7.1.2)\n",
      "Requirement already satisfied: toml in c:\\users\\rj\\anaconda3\\lib\\site-packages (from streamlit) (0.10.1)\n",
      "Collecting gitpython\n",
      "  Downloading GitPython-3.1.17-py3-none-any.whl (166 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from streamlit) (8.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\rj\\anaconda3\\lib\\site-packages (from streamlit) (20.4)\n",
      "Collecting astor\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting pyarrow; python_version < \"3.9\"\n",
      "  Downloading pyarrow-4.0.0-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\rj\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (3.2.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\rj\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (2.11.2)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\rj\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from python-dateutil->streamlit) (1.15.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\rj\\anaconda3\\lib\\site-packages (from tzlocal->streamlit) (2020.1)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from validators->streamlit) (4.4.2)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
      "Requirement already satisfied: ipykernel>=5.1.2; python_version >= \"3.4\" in c:\\users\\rj\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (5.3.4)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (7.5.1)\n",
      "Requirement already satisfied: pathtools>=0.1.1 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from watchdog; platform_system != \"Darwin\"->streamlit) (0.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from requests->streamlit) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from requests->streamlit) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from requests->streamlit) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from requests->streamlit) (3.0.4)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from packaging->streamlit) (2.4.7)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from jsonschema->altair>=3.2.0->streamlit) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from jsonschema->altair>=3.2.0->streamlit) (20.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rj\\anaconda3\\lib\\site-packages (from jsonschema->altair>=3.2.0->streamlit) (50.3.1.post20201107)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\rj\\anaconda3\\lib\\site-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\rj\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (6.1.7)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (7.19.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.0.8)\n",
      "Collecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (19.0.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.6.3)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\rj\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.17.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (3.0.8)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\rj\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: pygments in c:\\users\\rj\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (2.7.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\rj\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.1.4)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\rj\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (227)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\rj\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.1)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\rj\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.0.7)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\rj\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\rj\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (20.1.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\rj\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.0)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.7)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\rj\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\rj\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.2.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
      "Requirement already satisfied: testpath in c:\\users\\rj\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\rj\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\rj\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.14.3)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\rj\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.2)\n",
      "Requirement already satisfied: async-generator in c:\\users\\rj\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.10)\n",
      "Requirement already satisfied: webencodings in c:\\users\\rj\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rj\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.20)\n",
      "Building wheels for collected packages: blinker\n",
      "  Building wheel for blinker (setup.py): started\n",
      "  Building wheel for blinker (setup.py): finished with status 'done'\n",
      "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13454 sha256=6b11e95f6446ae088b167decd9b4965a5bfc2278175cd759c5a62224b9c380e8\n",
      "  Stored in directory: c:\\users\\rj\\appdata\\local\\pip\\cache\\wheels\\b7\\a5\\68\\fe632054a5eadd531c7a49d740c50eb6adfbeca822b4eab8d4\n",
      "Successfully built blinker\n",
      "Installing collected packages: altair, blinker, tzlocal, validators, pydeck, base58, smmap, gitdb, gitpython, astor, pyarrow, streamlit\n",
      "Successfully installed altair-4.1.0 astor-0.8.1 base58-2.1.0 blinker-1.4 gitdb-4.0.7 gitpython-3.1.17 pyarrow-4.0.0 pydeck-0.6.2 smmap-4.0.0 streamlit-0.82.0 tzlocal-2.1 validators-0.18.2\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# EDA Pkgs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import json\n",
    "from tweepy import OAuthHandler\n",
    "import re\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import openpyxl\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Hide Warnings\n",
    "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
    "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "# Viz Pkgs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import seaborn as sns\n",
    "#sns.set_style('darkgrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE = \"\"\"\n",
    "<style>\n",
    "img {\n",
    "    max-width: 100%;\n",
    "}\n",
    "</style> \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"  \"\"\"\n",
    "    #st.title(\"Live twitter Sentiment analysis\")\n",
    "    #st.subheader(\"Select a topic which you'd like to get the sentiment analysis on :\")\n",
    "\n",
    "    html_temp = \"\"\"\n",
    "\t<div style=\"background-color:tomato;\"><p style=\"color:white;font-size:40px;padding:9px\">Live Twitter Sentiment analysis using Hash Tags</p></div>\n",
    "\t\"\"\"\n",
    "    st.markdown(html_temp, unsafe_allow_html=True)\n",
    "    st.subheader(\"Select a topic/ hashtags which you'd like to get the sentiment analysis on :\")\n",
    "\n",
    "    ################# Twitter API Connection #######################\n",
    "    consumer_key = \"buazbS6FoADb5217RO6XiXeOh\"\n",
    "    consumer_secret = \"9Xlei2cX61sEoRpSZ6c5K8p0FGVGtfbZ7VxFHQete0JaQxRkuV\"\n",
    "    access_token = \"871033911949656064-qzhz5pzPryKDp0kSdw3PrBjofGdDT8X\"\n",
    "    access_token_secret = \"pS1sCbAmLxu5dnJKjpSwF5twa8tf6ZTQ7O4ZVYlS0JcXj\"\n",
    "\n",
    "\n",
    "\n",
    "    # Use the above credentials to authenticate the API.\n",
    "\n",
    "    auth = tweepy.OAuthHandler( consumer_key , consumer_secret )\n",
    "    auth.set_access_token( access_token , access_token_secret )\n",
    "    api = tweepy.API(auth)\n",
    "    ################################################################\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"Date\",\"User\",\"IsVerified\",\"Tweet\",\"Likes\",\"RT\",'User_location'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a Function to extract tweets:\n",
    "def get_tweets(Topic,Count):\n",
    "        i=0\n",
    "        #my_bar = st.progress(100) # To track progress of Extracted tweets\n",
    "        for tweet in tweepy.Cursor(api.search, q=Topic,count=5000, lang=\"en\",exclude='retweets').items():\n",
    "            #time.sleep(0.1)\n",
    "            #my_bar.progress(i)\n",
    "            df.loc[i,\"Date\"] = tweet.created_at\n",
    "            df.loc[i,\"User\"] = tweet.user.name\n",
    "            df.loc[i,\"IsVerified\"] = tweet.user.verified\n",
    "            df.loc[i,\"Tweet\"] = tweet.text\n",
    "            df.loc[i,\"Likes\"] = tweet.favorite_count\n",
    "            df.loc[i,\"RT\"] = tweet.retweet_count\n",
    "            df.loc[i,\"User_location\"] = tweet.user.location\n",
    "            #df.to_csv(\"TweetDataset.csv\",index=False)\n",
    "            #df.to_excel('{}.xlsx'.format(\"TweetDataset\"),index=False)   ## Save as Excel\n",
    "            i=i+1\n",
    "            if i>Count:\n",
    "                break\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciton to analyze Sentiment\n",
    "def analyze_sentiment(tweet):\n",
    "        analysis = TextBlob(tweet)\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'Positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'Neutral'\n",
    "        else:\n",
    "            return 'Negative'\n",
    "    \n",
    "    #Function to Pre-process data for Worlcloud\n",
    "def prepCloud(Topic_text,Topic):\n",
    "        Topic = str(Topic).lower()\n",
    "        Topic=' '.join(re.sub('([^0-9A-Za-z \\t])', ' ', Topic).split())\n",
    "        Topic = re.split(\"\\s+\",str(Topic))\n",
    "        stopwords = set(STOPWORDS)\n",
    "        stopwords.update(Topic) ### Add our topic in Stopwords, so it doesnt appear in wordClous\n",
    "        ###\n",
    "        text_new = \" \".join([txt for txt in Topic_text.split() if txt not in stopwords])\n",
    "        return text_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-16 18:57:02.569 WARNING root: \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\RJ\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator(_root_container=0, _provided_cursor=None, _parent=None, _block_type=None, _form_data=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('Logo1.png')\n",
    "st.image(image, caption='Twitter for Analytics',use_column_width=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Input from user :\n",
    "Topic = str()\n",
    "Topic = str(st.text_input(\"Enter the Hash Tags you are interested in (Press Enter once done)\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(Topic) > 0 :\n",
    "        \n",
    "        # Call the function to extract the data. pass the topic and filename you want the data to be stored in.\n",
    "        with st.spinner(\"Please wait, Tweets are being extracted\"):\n",
    "            get_tweets(Topic , Count=200)\n",
    "        st.success('Tweets have been Extracted !!!!')    \n",
    "           \n",
    "    \n",
    "        # Call function to get Clean tweets\n",
    "        df['clean_tweet'] = df['Tweet'].apply(lambda x : clean_tweet(x))\n",
    "    \n",
    "        # Call function to get the Sentiments\n",
    "        df[\"Sentiment\"] = df[\"Tweet\"].apply(lambda x : analyze_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Summary of the Tweets\n",
    "st.write(\"Total Tweets Extracted for Topic '{}' are : {}\".format(Topic,len(['Tweet'])))\n",
    "st.write(\"Total Positive Tweets are : {}\".format(len([[\"Sentiment\"]==\"Positive\"])))\n",
    "st.write(\"Total Negative Tweets are : {}\".format(len([[\"Sentiment\"]==\"Negative\"])))\n",
    "st.write(\"Total Neutral Tweets are : {}\".format(len([[\"Sentiment\"]==\"Neutral\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the Extracted Data : \n",
    "if st.button(\"See the Extracted Data\"):\n",
    "            #st.markdown(html_temp, unsafe_allow_html=True)\n",
    "            st.success(\"Below is the Extracted Data :\")\n",
    "            st.write(df.head(50))\n",
    "        \n",
    "        \n",
    "        # get the countPlot\n",
    "if st.button(\"Get Count Plot for Different Sentiments\"):\n",
    "            st.success(\"Generating A Count Plot\")\n",
    "            st.subheader(\" Count Plot for Different Sentiments\")\n",
    "            st.write(sns.countplot(df[\"Sentiment\"]))\n",
    "            st.pyplot()\n",
    "        \n",
    "        # Piechart \n",
    "if st.button(\"Get Pie Chart for Different Sentiments\"):\n",
    "            st.success(\"Generating A Pie Chart\")\n",
    "            a=len(df[df[\"Sentiment\"]==\"Positive\"])\n",
    "            b=len(df[df[\"Sentiment\"]==\"Negative\"])\n",
    "            c=len(df[df[\"Sentiment\"]==\"Neutral\"])\n",
    "            d=np.array([a,b,c])\n",
    "            explode = (0.1, 0.0, 0.1)\n",
    "            st.write(plt.pie(d,shadow=True,explode=explode,labels=[\"Positive\",\"Negative\",\"Neutral\"],autopct='%1.2f%%'))\n",
    "            st.pyplot()\n",
    "            \n",
    "            \n",
    "        # get the countPlot Based on Verified and unverified Users\n",
    "if st.button(\"Get Count Plot Based on Verified and unverified Users\"):\n",
    "            st.success(\"Generating A Count Plot (Verified and unverified Users)\")\n",
    "            st.subheader(\" Count Plot for Different Sentiments for Verified and unverified Users\")\n",
    "            st.write(sns.countplot(df[\"Sentiment\"],hue=df.IsVerified))\n",
    "            st.pyplot()\n",
    "        \n",
    "        \n",
    "        ## Points to add 1. Make Backgroud Clear for Wordcloud 2. Remove keywords from Wordcloud\n",
    "        \n",
    "        \n",
    "        # Create a Worlcloud\n",
    "if st.button(\"Get WordCloud for all things said about {}\".format(Topic)):\n",
    "            st.success(\"Generating A WordCloud for all things said about {}\".format(Topic))\n",
    "            text = \" \".join(review for review in df.clean_tweet)\n",
    "            stopwords = set(STOPWORDS)\n",
    "            text_newALL = prepCloud(text,Topic)\n",
    "            wordcloud = WordCloud(stopwords=stopwords,max_words=800,max_font_size=70).generate(text_newALL)\n",
    "            st.write(plt.imshow(wordcloud, interpolation='bilinear'))\n",
    "            st.pyplot()\n",
    "        \n",
    "        \n",
    "        #Wordcloud for Positive tweets only\n",
    "if st.button(\"Get WordCloud for all Positive Tweets about {}\".format(Topic)):\n",
    "            st.success(\"Generating A WordCloud for all Positive Tweets about {}\".format(Topic))\n",
    "            text_positive = \" \".join(review for review in df[df[\"Sentiment\"]==\"Positive\"].clean_tweet)\n",
    "            stopwords = set(STOPWORDS)\n",
    "            text_new_positive = prepCloud(text_positive,Topic)\n",
    "            #text_positive=\" \".join([word for word in text_positive.split() if word not in stopwords])\n",
    "            wordcloud = WordCloud(stopwords=stopwords,max_words=800,max_font_size=70).generate(text_new_positive)\n",
    "            st.write(plt.imshow(wordcloud, interpolation='bilinear'))\n",
    "            st.pyplot()\n",
    "        \n",
    "        \n",
    "        #Wordcloud for Negative tweets only       \n",
    "if st.button(\"Get WordCloud for all Negative Tweets about {}\".format(Topic)):\n",
    "            st.success(\"Generating A WordCloud for all Positive Tweets about {}\".format(Topic))\n",
    "            text_negative = \" \".join(review for review in df[df[\"Sentiment\"]==\"Negative\"].clean_tweet)\n",
    "            stopwords = set(STOPWORDS)\n",
    "            text_new_negative = prepCloud(text_negative,Topic)\n",
    "            #text_negative=\" \".join([word for word in text_negative.split() if word not in stopwords])\n",
    "            wordcloud = WordCloud(stopwords=stopwords,max_words=800,max_font_size=70).generate(text_new_negative)\n",
    "            st.write(plt.imshow(wordcloud, interpolation='bilinear'))\n",
    "            st.pyplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "    st.sidebar.header(\"About App\")\n",
    "    st.sidebar.info(\"A Real Time Twitter Sentiment analysis using Hash Tags Project which will scrap twitter for the topic selected by the user. The extracted tweets will then be used to determine the Sentiments of those tweets. \\\n",
    "                    The different Visualizations will help us get a feel of the overall mood of the people on Twitter regarding the topic we select.\")\n",
    "    st.sidebar.text(\"Built with Streamlit and Heroku\")\n",
    "    \n",
    "    st.sidebar.header(\"For Any Queries/Suggestions Please reach out at :\")\n",
    "    st.sidebar.info(\"jainishflashecube@gmail.com\")\n",
    "    #st.sidebar.subheader(\"Scatter-plot setup\")\n",
    "    #box1 = st.sidebar.selectbox(label= \"X axis\", options = numeric_columns)\n",
    "    #box2 = st.sidebar.selectbox(label=\"Y axis\", options=numeric_columns)\n",
    "    #sns.jointplot(x=box1, y= box2, data=df, kind = \"reg\", color= \"red\")\n",
    "    #st.pyplot()\n",
    "\n",
    "\n",
    "\n",
    "if st.button(\"Exit\"):\n",
    "        st.balloons()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
